---
title: "R Notebook for Exploration of US House Expenditures: 'purpose' variable"
output: html_notebook
---
  
    
    This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook for exploration of US House Expenditures. Data were obtained from the ProPublica website here:  
[ProPublica](https://projects.propublica.org/represent/expenditures)  
  
    
    The code below is for cleaning the variable: purpose
  
    
    Setup the root directory.
```{r "setup", include = FALSE}

require("knitr")

opts_knit$set(root.dir = "/Users/mdturse/Desktop/Analytics/house_expenditures/supermdat_general_exploration")

```
  
    
    Set "wd" as the working directory.
```{r}

wd <- getwd()
wd

```
  
    
    Load the packages to be used.
```{r, message=FALSE, warning=FALSE}

library("tidyverse")          # data manipulation
library("lazyeval")           # writing functions
library("rlang")              # writing functions
library("stringr")            # string manipulation
library("lubridate")          # date manipulation
library("stringdist")         # calculating string (character) distances
library("tidytext")           # text manipulation
library("hunspell")           # used for spell checking
# library("caret")              # used pre-processing the data
library("factoextra")         # clustering
library("cluster")            # clustering

```
  
    
    Session Info.
```{r}

sessionInfo()

```
  
    
    First, source the function to compute the distances (Jaro-Winker distance) between every pair of levels in a particular variable.
```{r}

rm(AllQtrs)

source(paste0(wd, "/1_func_dist.R"))

```
  
    
    Explore distances for the variable: purpose
    
    Even with the Jaro-Winker threshold at 0.1 (i.e., jw_socre <= 0.1), there are still an extremely large amount of "close" matches (~138,000).
```{r}

# SpellingAdjust_Program <- readRDS(paste0(wd,
#                                          "/ProcessedData/",
#                                          "SpellingAdjust_Program.Rds"
#                                          )
#                                   )

rm(dist_program, LookupProgram, SpellingAdjust_Office)


str(SpellingAdjust_Program)

dist_purpose <- func_dist(data_ = SpellingAdjust_Program,
                          var_ = purpose,
                          method_ = "jw",
                          p = 0.1
                          )

message("distinct levels of purpose")
nrow(select(distinct(SpellingAdjust_Program,
                     purpose
                     )
            )
     )

message("rows of the distance matrix")
nrow(dist_purpose)

message("rows of the distance matrix with the jw_socre <= 0.1")
nrow(filter(dist_purpose,
            jw_score <= 0.1
            ) %>%
       arrange(jw_score)
     )

View(filter(dist_purpose,
            jw_score <= 0.1
            ) %>%
       arrange(jw_score)
     )

```
  
    
    Inspecting "purpose" for mis-spellings and spelling variations.
    
    purpose_NoSymbs: This is the result of removing common "extraneous" text (e.g., numerics, punctuation, dollar sign, "qty") that seen when eyeballing dist_purpose (the result of the distance calculation).  
      
    As a result, running func_dist again, and setting the resulting Jaro-Winker threshold at 0.1 (i.e., jw_socre <= 0.1), we have ~2,000 matches.  Much better, but still a lot to sift through manually.
```{r}

# SpellingAdjust_Program <- readRDS(paste0(wd,
#                                          "/ProcessedData/",
#                                          "SpellingAdjust_Program.Rds"
#                                          )
#                                   )


fix_list1 <- c("[[:digit:]]" = "",
               "[[:punct:]]" = "",
               "\\$" = "",
               "qty" = ""
               )


purpose_NoSymbs <- select(SpellingAdjust_Program,
                          purpose
                          ) %>% 
  distinct() %>% 
  mutate(purpose_mod = str_replace_all(purpose,
                                       fix_list1
                                       ) %>% 
           str_replace_all("\\s+",
                           " "
                           ) %>% 
           str_trim(side = "both"),
         RowNum = row_number()
         )


dist_purpose_NoSymbs <- func_dist(data_ = purpose_NoSymbs,
                                  var_ = purpose_mod,
                                  method_ = "jw",
                                  p = 0.1
                                  )

message("rows of the distance matrix with the jw_socre <= 0.1")
nrow(filter(dist_purpose_NoSymbs,
            jw_score <= 0.1
            ) %>%
       arrange(jw_score)
     )

View(filter(dist_purpose_NoSymbs,
            jw_score <= 0.1
            ) %>%
       arrange(jw_score)
     )

```
  
    
    Next, source the function func_TopMisSpel to get common mis-spellings (based on hunspell::hunspell_check).
```{r}

source(paste0(wd, "/3_func_TopMisSpel.R"))

```
  
    
    Check for common mis-spellings or spelling variations in purpose_mod.  Fixing all mis-spellings that occur 10 or more times will correct ~61% of all mis-spellings.
```{r}

str(purpose_NoSymbs)

purpose_mod_TopMisSpel <- func_TopMisSpel(data_ = purpose_NoSymbs,
                                          var_ = purpose_mod
                                          )


str(purpose_mod_TopMisSpel)
View(purpose_mod_TopMisSpel)
head(purpose_mod_TopMisSpel, 50)

```
  
    
    Correcting the spelling for those words that have 10 or more mis-spellings.  This was a tedious manual process.
```{r}

str(purpose_NoSymbs)

fix_list2 <- c("\\badmin\\b" = "administrative",
               "\\baff\\b" = "affairs",
               "\\bass(is){0,1}t{0,1}\\b" = "assistant",
               "\\bcasewkr\\b" = "case worker",
               "\\bchf\\b" = "chief",
               "\\bcheif\\b" = "chief",
               "\\bcao\\b" = "chief administrative officer",
               "\\bcmte\\b" = "committee",
               "\\bcommun(ica){0,1}\\b" = "communications",
               "\\bconst(it){0,1}\\b" = "constituent",
               "\\bconst(i){0,1}\\b" = "constituent",
               "\\bcontr\\b" = "contracts",
               "\\bcoord{0,1}\\b" = "coordinator",
               "\\bcorr(es){0,1}p{0,1}\\b" = "correspondent",
               "\\bcos\\b" = "chief of staff",
               "\\bcouns{0,1}\\b" = "counselor",
               "\\bdama\\b" = "disability assistance and memorial affairs",
               "\\bdep\\b" = "deputy",
               "\\bdpty\\b" = "deputy",
               "\\bdir(ecto){0,1}\\b" = "director",
               "\\beo\\b" = "executive order",
               "\\bexc\\b" = "executive",
               "\\beq\\b" = "equipment",
               "\\bfc\\b" = "full committee",
               "\\bhardw\\b" = "hardware",
               "\\binv\\b" = "investigations",
               "\\bld\\b" = "legislative director",
               "\\blegist{0,1}\\b" = "legislative",
               "\\bleg\\b" = "legislative",
               "\\blias(i){0,1}on\\b" = "liaison",
               "\\bmgmt\\b" = "management",
               "\\bmn{0,1}gr\\b" = "manager",
               "\\bmem\\b" = "member",
               "\\bmbr\\b" = "member",
               "\\bofc\\b" = "office",
               "\\boper\\b" = "operations",
               "\\bops\\b" = "operations",
               "\\bproj\\b" = "projects",
               "\\bpurch\\b" = "purchases",
               "\\brepub\\b" = "republican",
               "\\bsched\\b" = "scheduler",
               "\\bsec(ty){0,1}\\b" = "secretary",
               "\\bsaa\\b" = "sergeant at arms",
               "\\bsvc{0,1}s{0,1}\\b" = "services",
               "\\bserv{0,1}\\b" = "services",
               "\\bsoftw\\b" = "software",
               "\\bspeechwriter\\b" = "speech writer",
               "\\bsta{0,1}f\\b" = "staff",
               "\\bstrat\\b" = "strategic",
               "\\bsubc(om){0,1}(omm){0,1}\\b" = "subcommittee",
               "\\bsyst\\b" = "systems",
               "\\btelecomsrv\\b" = "telecommunications services"
               )


purpose_FixCmnMisSpel <- 
  mutate(purpose_NoSymbs,
         purpose_mod2 = str_replace_all(purpose_mod,
                                        fix_list2
                                        )
         ) %>% 
  select(RowNum,
         purpose_mod2
         )


str(purpose_FixCmnMisSpel)

```
  
    
    Check for common mis-spellings or spelling variations in purpose_mod2.
```{r}

str(purpose_FixCmnMisSpel)


purpose_mod2_TopMisSpel <- func_TopMisSpel(data_ = purpose_FixCmnMisSpel,
                                           var_ = purpose_mod2
                                           )


View(head(purpose_mod2_TopMisSpel, 500))
head(purpose_mod2_TopMisSpel, 50)

```
  
    
    Calculate distance on the "cleaned" data using the Jaro-Winker distance. "Fixing" the common spelling errors has produced ~2,544 matches taht are still below the Jaro-Winkler distance metric of 0.1. It looks like these are mostly "uncommon" spelling mistakes (e.g., spelling "deputy" as "depty") or adding/removing a letter (e.g., "special project" vs. "special projects")
```{r}

dist_purposeFix_jw <- func_dist(data_ = purpose_FixCmnMisSpel,
                                var_ = purpose_mod2,
                                method_ = "jw",
                                p = 0.1
                                )

str(dist_purposeFix_jw)


filter(dist_purposeFix_jw,
       jw_score <= 0.1
       ) %>% 
  nrow()


View(filter(dist_purposeFix_jw,
            jw_score <= 0.1
            ) %>% 
       arrange(jw_score)
     )

```
  
    
    Calculate distance on the "cleaned" data using the Soundex distance.
```{r}

dist_purposeFix_sndx <- func_dist(data_ = purpose_FixCmnMisSpel,
                                  var_ = purpose_mod2,
                                  method_ = "soundex"
                                  )

str(dist_purposeFix_sndx)

```
  
    
    Join distance calculations done with Jaro-Winker and done with Soundex.
```{r}

dist_purposeFix_Full <- inner_join(dist_purposeFix_jw,
                                   select(dist_purposeFix_sndx,
                                          -var_og
                                          ),
                                   by = c("level1" = "level1",
                                          "level2" = "level2"
                                          )
                                   ) %>% 
  mutate(l1_FrstChr = substr(level1, 1, 1),
         l2_FrstChr = substr(level2, 1, 1),
         l1_nChr = nchar(level1),
         l2_nChr = nchar(level2)
         )


message("dist_purposeFix_Full")
str(dist_purposeFix_Full)


View(filter(dist_purposeFix_Full,
            jw_score <= 0.1
            ) %>% 
       arrange(jw_score)
     )


View(filter(dist_purposeFix_Full,
            jw_score <= 0.04
            ) %>% 
       arrange(jw_score)
     )


dist_purposeFix_Full_Pt04 <- filter(dist_purposeFix_Full,
                                    jw_score <= 0.04
                                    )


message("dist_purposeFix_Full_Pt04")
str(dist_purposeFix_Full_Pt04)

```
  
    
    "En masse" correction if jw_score is <= 0.04 (this value was chosen by eyeballing the scores).
```{r}

message("purpose_FixCmnMisSpel")
str(purpose_FixCmnMisSpel)


purpose_FixEnMasse <- left_join(purpose_FixCmnMisSpel,
                                select(dist_purposeFix_Full_Pt04,
                                       level1,
                                       level2,
                                       jw_score
                                       ),
                                by = c("purpose_mod2" = "level2")
                                ) %>% 
  mutate(purpose_mod3 = ifelse(is.na(level1),
                               purpose_mod2,
                               level1
                               )
         )


message("purpose_FixEnMasse")
str(purpose_FixEnMasse)
View(head(purpose_FixEnMasse, 500))

```
  
    
    Check for common mis-spellings or spelling variations in purpose_mod3.
```{r}

str(purpose_FixEnMasse)


purpose_mod3_TopMisSpel <- func_TopMisSpel(data_ = purpose_FixEnMasse,
                                           var_ = purpose_mod3
                                           )


View(head(purpose_mod3_TopMisSpel, 500))
head(purpose_mod3_TopMisSpel, 50)

```
  
    
    Update spelling of of the purpose in the larger SpellingAdjust_Program data frame.
```{r}

message("SpellingAdjust_Program")
str(SpellingAdjust_Program)

str(fix_list1)
str(fix_list2)

str(dist_purposeFix_Full_Pt04)


dist_purposeFix_Full_Pt04_mins <- 
  select(dist_purposeFix_Full_Pt04,
         level1,
         level2,
         jw_score
         ) %>% 
  arrange(level2,
          jw_score,
          level1
          ) %>% 
  group_by(level2) %>% 
  mutate(GroupRowNum = row_number()
         ) %>% 
  filter(GroupRowNum == 1) %>% 
  select(-jw_score,
         -GroupRowNum
         )
  

SpellingAdjust_Purpose <- 
  mutate(SpellingAdjust_Program,
         purpose_temp = str_replace_all(purpose,
                                        fix_list1
                                        ) %>% 
           str_replace_all(fix_list2) %>% 
           str_replace_all("\\s+",
                           " "
                           ) %>% 
           str_trim(side = "both")
         ) %>%
  left_join(dist_purposeFix_Full_Pt04_mins,
            by = c("purpose_temp" = "level2")
            ) %>%
  mutate(purpose_cc = ifelse(is.na(level1),
                             purpose_temp,
                             level1
                             ),
         purpose_cc_factor = as.factor(purpose_cc)
         ) %>%
  select(-purpose_temp,
         -level1
         )


message("SpellingAdjust_Purpose")
str(SpellingAdjust_Purpose)
# saveRDS(SpellingAdjust_Purpose, 
#         paste0(wd,
#                "/ProcessedData/",
#                "SpellingAdjust_Purpose.Rds"
#                )
#         )

```
  
    
    Compute distance of new "purpose" variable ("purpose_cc"). This shows that there are still mis-spellings and spelling variations that exist. It also shows that even with "proper" spellings, there are many enteries in the "purpose" variable that are similar.
```{r}

dist_purpose_FixCmnMisSpel <- func_dist(data_ = SpellingAdjust_Purpose,
                                        var_ = purpose_cc,
                                        method_ = "jw",
                                        p = 0.1
                                        ) %>%
  mutate(l1_FrstChr = substr(level1, 1, 1),
         l2_FrstChr = substr(level2, 1, 1),
         l1_NumChrs = nchar(level1),
         l2_NumChrs = nchar(level2),
         RowNum = row_number()
         )


message("rows of the distance matrix with the jw_score <= 0.1")
nrow(filter(dist_purpose_FixCmnMisSpel,
            jw_score <= 0.1
            ) %>%
       arrange(jw_score)
     )


View(filter(dist_purpose_FixCmnMisSpel,
            jw_score <= 0.1
            ) %>%
       arrange(jw_score)
     )

```
  
    
    Using simple hierarchical clustering on the "purpose distances" to highlight which "purpose" entries are similar. A potential use of this would be to do analyses on the clusters instead of one the actual "purpose" entries themselves.
      
    First, create the distance matrix.
```{r}

str(SpellingAdjust_Purpose)

purpose_cc_distinct <- select(SpellingAdjust_Purpose,
                              purpose_cc
                              ) %>% 
  distinct() 

# The step below is done because stringdist::stringdistmatrix will not function properly with NA values
purpose_cc_distinct[is.na(purpose_cc_distinct)] <- "--"

str(purpose_cc_distinct)
View(arrange(purpose_cc_distinct,
             purpose_cc
             )
     )

View(group_by(SpellingAdjust_Purpose,
              purpose_cc
              ) %>% 
       summarise(Cnt_Num = n(),
                 Cnt_Pct = Cnt_Num / nrow(SpellingAdjust_Purpose)
                 ) %>% 
       arrange(purpose_cc)
     )


distmtrx_purpose_cc <- stringdistmatrix(purpose_cc_distinct$purpose_cc,
                                        useNames = "strings",
                                        method = "jw",
                                        p = 0.1
                                        )


str(distmtrx_purpose_cc)

```
  
    
    Using simple hierarchical clustering on the "purpose distances" to highlight which "purpose" entries are similar.  A potential use of this would be to do analyses on the clusters instead of one the actual "purpose" entries themselves.
      
    Second, perform the hierarchical clustering. k = 1000 is arbitrarily chosen, but does a relatively accurate job of creating the clusters with similar observations.
```{r}

hc <- hclust(as.dist(distmtrx_purpose_cc)
             )

str(hc)


ctree_purpose_cc_k1000 <- cutree(hc, k = 1000)
str(ctree_purpose_cc_k1000)

```


    Using simple hierarchical clustering on the "purpose distances" to highlight which "purpose" entries are similar.  A potential use of this would be to do analyses on the clusters instead of one the actual "purpose" entries themselves.
      
    Third, join back data that makes interpreting the clusters easier (e.g., what specific "purpose" text is entered).
```{r}

purpose_cc_df_k1000 <- data.frame(purpose_cc_distinct,
                                  ctree_purpose_cc_k1000
                                  ) %>% 
  rename(cluster = ctree_purpose_cc_k1000)


str(purpose_cc_df_k1000)
View(purpose_cc_df_k1000)


purpose_cc_cnts <- group_by(purpose_cc_df_k1000,
                            cluster
                            ) %>% 
  summarise(Cnt_Num = n(),
            Cnt_Pct = Cnt_Num / nrow(purpose_cc_df_k1000)
            ) %>% 
  arrange(desc(Cnt_Pct)
          )

str(purpose_cc_cnts)
View(purpose_cc_cnts)


purpose_cc_df_k1000_cnts <- left_join(purpose_cc_df_k1000,
                                      purpose_cc_cnts,
                                      by = c("cluster" = "cluster")
                                      )


str(purpose_cc_df_k1000_cnts)

View(arrange(purpose_cc_df_k1000_cnts,
             desc(Cnt_Num),
             cluster,
             purpose_cc
             )
     )

```
  
    
    Remove unneeded files.
```{r}

rm(list = ls(pattern = "dist_")
   )

rm(list = ls(pattern = "purpose_")
   )

rm(list = ls(pattern = "fix_")
   )

rm(hc, SpellingAdjust_Program)

```


